# -*- coding: utf-8 -*-
"""bimain.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_AR4dcc1V3Un-QRM-xVGEkS95FZl5Lw7

# ***Data Description***
Here we have a housing dataset.
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from xgboost import XGBRegressor
# %matplotlib inline

df=pd.read_csv('/content/drive/MyDrive/BIProject/USA_Housing.csv')

df.head()

df.info()

df.describe()

df.shape

df.columns

"""# ***Exploratory Data Analysis***

1. Finding unwanted columns

  There are no unwanted columns to remove

2. Finding missing values
"""

features_na = [features for features in df.columns if df[features].isnull().sum() > 0]
for feature in features_na:
  print(feature, np.round(df[feature].isnull().mean(),4), '% missing values')
else:
  print("No missing value found")

"""3. Exploring categorical features"""

categorical_features = [feature for feature in df.columns if ((df[feature].dtypes=='O') & (feature not in ['GLD']))]
categorical_features

for feature in categorical_features:
  print("The categorical feature is {} and number of categories are {}".format(feature, len(df[feature].unique())))

"""4. Find categorical feature distribution

  N/A

5. Relationship between categorical features and label

  N/A

6. Exploring the numerical features
"""

numerical_features = [feature for feature in df.columns if ((df[feature].dtypes!='O') & (feature not in ['GLD']))]
print('There are {} numerical features'.format(len(numerical_features)))

df[numerical_features].head()

"""7. Find discrete numerical features"""

discrete_feature = [feature for feature in numerical_features if len(df[feature].unique())<25]
print("There are {} discrete variables".format(len(discrete_feature)))

"""8. Relationship between discrete numerical features and label

  N/A

9. Find continuous numerical features
"""

continuous_features = [feature for feature in numerical_features if feature not in discrete_feature+['GOD']]
print("There are {} continuous numerical features".format(len(continuous_features)))

"""10. Distribution of continuous numerical features"""

plt.figure(figsize=(20,60), facecolor='white')
plotnumber = 1
for continuous_feature in continuous_features:
  ax = plt.subplot(12,3,plotnumber)
  sns.distplot(df[continuous_feature])
  plt.xlabel(continuous_feature)
  plotnumber+=1
plt.show()

"""11. Relationship between continuous numerical features and label"""

plt.figure(figsize=(20,60), facecolor='white')
plotnumber = 1
for feature in continuous_features:
  data = df.copy()
  ax = plt.subplot(12,3,plotnumber)
  plt.scatter(data[feature], data['Price'])
  plt.xlabel(feature)
  plt.ylabel('Price')
  plt.title(feature)
  plotnumber+=1
plt.show()

"""12. Finding outliers in numerical features"""

plt.figure(figsize=(20,60), facecolor='white')
plotnumber = 1
for numerical_feature in numerical_features:
  ax = plt.subplot(12,3,plotnumber)
  sns.boxplot(df[numerical_feature])
  plt.xlabel(numerical_feature)
  plotnumber+=1
plt.show()

"""13. Exploring the correlation between numerical features"""

cor_mat=df.corr()
fig = plt.figure(figsize=(15,7))
sns.heatmap(cor_mat,annot=True)
plt.show()

print(cor_mat['Price'].sort_values(ascending=False), '\n')

"""# ***Feature Engineering***"""

df2 = df.copy()
df2.drop(['Address'], axis=1, inplace=True)
df2.head()

X = df2.drop(['Price'], axis=1)
y = df2['Price']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4, random_state=101)

X_train

X_test

len(X_train)

len(X_test)

"""# ***Testing Model***"""

from sklearn.linear_model import LinearRegression

lm = LinearRegression()

lm.fit(X_train,y_train)

coeff_df = pd.DataFrame(lm.coef_,X.columns,columns=['Coefficient'])
coeff_df

predictions = lm.predict(X_test)
predictions

y_test

score1 = lm.score(X_train, y_train)
score1

score = lm.score(X_test, y_test)
score

plt.scatter(y_test,predictions)

sns.distplot((y_test-predictions),bins=50);

def predict(A,B,C,D,E):
  mydf = pd.DataFrame({"Avg. Area Income":[A],
                      "Avg. Area House Age":[B],
                      "Avg. Area Number of Rooms":[C],
                      "Avg. Area Number of Bedrooms":[D],
                       "Area Population":[E]})
  pred = lm.predict(mydf)
  return(pred[0])
predict(79545,5.68,7,4,23086)